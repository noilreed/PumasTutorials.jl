---
title: Discrete Response Models
author: Vijay Ivaturi, Chris Rackauckas
date: July 19th, 2019
---

# Introduction

In this tutorial we will go over the simulation of discrete responses. Many
pharmacometrics scenarios have observables, such as pain scores or counts,
which necessarily have to be discrete. Handling this discreteness can be
paramount to getting an appropriate data fit and to properly understand the
variation.

Luckily, in Pumas, discrete outputs are handled no differently from the rest
of the Pumas toolchain. In Pumas, to have a discrete distribution as output,
simply have that your `derived` or `observed` variables come from a discrete
distribution like a `Poisson` process.



## Poisson Response Example

Next let's use a `Poisson` counting process in our model. Here we generate a
population where everyone is receiving the same doses as a covariate.

```julia
pop = Population(map(i -> Subject(id=i,cvs=(dose = i.*10,),time=[0.0]),1:10))
```

Now we define our model without dynamics, and directly use the dose information
to predict the count for some observable `dv`:

```julia
poisson_model = @model begin
  @param begin
    tvbase ∈ RealDomain(init=3.0, lower=0.1)
    d50 ∈ RealDomain(init=50, lower=0.1)
    Ω  ∈ PSDDomain(fill(0.1, 1, 1))
  end

  @random begin
    η ~ MvNormal(Ω)
  end

 @covariates dose

  @pre begin
    _dose = dose
    baseline = tvbase*exp(η[1])
  end

  @derived begin
    dv ~ @. Poisson(baseline*(1-_dose/(_dose + d50)))
  end
end
```

and simulate runs from the model:

```julia
sim = simobs(poisson_model,pop)
simdf = DataFrame(sim, include_events=false)
```

Here `dv` is an integer output probabilistically dependent on the dose.

Let's read the data back in to re-estimate the model parameters

```julia
poisson_pop = read_pumas(simdf, dvs=[:dv], cvs=[:dose], event_data=false)
```

```julia
poisson_res = fit(poisson_model,poisson_pop, init_param(poisson_model),Pumas.FOCE())
coeftable(poisson_res)
```

## Negative Binomial Example

Next let's use a `NegativeBinomial` counting process in our model. We will use an internal dataset
as an example.

```julia
pd_poisson = read_pumas(example_data("sim_poisson"), cvs = [:dose], event_data=false)
```

Now we define our model without dynamics, and directly use the dose information
to predict the count for some observable `dv`:

```julia
negativebinomial_model = @model begin
  @param begin
    θ₁ ∈ RealDomain(init=3.0, lower=0.1)
    θ₂ ∈ RealDomain(init=0.5, lower=0.1)
    ω  ∈ RealDomain(init=1.0, lower=0.0)
    θr  ∈ RealDomain(init=1.0, lower=0.0)
  end

  @random begin
    η ~ Normal(0.0, ω)
  end

  @pre begin
    baseline = θ₁*exp(η[1])
    d50 = θ₂
    dose_d50 = dose/(dose+d50)
    r = θr
  end

  @covariates dose

  @vars begin
    m = baseline*(1 - dose_d50)
    p = r/(m + r)
  end

  @derived begin
    dv ~ @. NegativeBinomial(r, p)
  end
end

param = init_param(negativebinomial_model)
```

and simulate runs from the model:

```julia
sim_negativebinomial = simobs(negativebinomial_model, pd_poisson, param; ensemblealg = EnsembleSerial())
```

Here `dv` is an integer output probabilistically dependent on the dose.

Let's read the data back in to re-estimate the model parameters


```julia
pd_negativebinomial  = Subject.(sim_negativebinomial)
```

And fit the data

```julia
ngebin_res = fit(negativebinomial_model, pd_negativebinomial, param, Pumas.FOCE())
coeftable(ngebin_res)
```

and make an inference

```julia
infer(ngebin_res)  |> coeftable
```

## Ordinal data example

Next, we look at a simple example for ordinal data. Again, we will use
an internal dataset

```julia
df = copy(CSV.read(example_data("pain_remed")))
```
The  dependent variable is coded 0:3 but `Categorical` distribution in julia
starts indexing at 1

```julia
df.painord .+= 1
```
Now, that we made this change, lets read the data into Pumas

```julia
data = read_pumas(df,
  dvs = [:painord],
  cvs = [:arm, :dose, :conc, :painord,:remed],
  event_data=false)
```

the ordinal model is below

```julia
ordinal_model = @model begin
  @param begin
    b₁    ∈ RealDomain(init=2.90692)
    b₂    ∈ RealDomain(init=-2.97771, lower=-1000000, upper=1)
    b₃    ∈ RealDomain(init=-2.7541 , lower=-1000000, upper=1)
    slope ∈ RealDomain(init=0.01)
    ω     ∈ RealDomain(init=sqrt(3.10532), lower = 0.001)
  end

  @random begin
    η ~ Normal(0.0, ω)
  end

  @covariates conc

  @pre begin
    effect = slope * conc
    #Logit of cumulative probabilities
    lge₀ = @. b₁ + η + effect
    lge₁ = @. lge₀ + b₂
    lge₂ = @. lge₁ + b₃

    #Probabilities of >=0 and >=1 and >=2
    pge₀ = @. exp(lge₀) / (1.0 + exp(lge₀))
    pge₁ = @. exp(lge₁) / (1.0 + exp(lge₁))
    pge₂ = @. exp(lge₂) / (1.0 + exp(lge₂))

    #Probabilities of Y=0,1,2,3
    p₀ = @. 1.0 - pge₀
    p₁ = @. pge₀ - pge₁
    p₂ = @. pge₁ - pge₂
    p₃ = @. pge₂
  end

  @derived begin
    painord ~ @. Categorical(p₀, p₁, p₂, p₃)
  end
end
```

```julia
ordinal_res = fit(ordinal_model, data, init_param(ordinal_model), Pumas.FOCE())
coeftable(ordinal_res)
```

and get the paremter precision with

```julia
ordinal_res |> infer |> coeftable
```

```julia{echo=false,skip="notebook"}
using PumasTutorials
PumasTutorials.tutorial_footer(WEAVE_ARGS[:folder],WEAVE_ARGS[:file])
```
